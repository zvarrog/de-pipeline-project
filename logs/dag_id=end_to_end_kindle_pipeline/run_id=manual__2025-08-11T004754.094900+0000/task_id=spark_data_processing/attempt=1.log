{"timestamp":"2025-08-11T00:48:03.086844","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-11T00:48:03.102141","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/process_kindle_reviews_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-11T00:48:04.923721","level":"info","event":"Starting docker container from image kindle-reviews-processor:latest","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:48:05.243174","level":"warning","event":"Using remote engine or docker-in-docker and mounting temporary volume from host is not supported. Falling back to `mount_tmp_dir=False` mode. You can set `mount_tmp_dir` parameter to False to disable mounting and remove the warning","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:48:07.650726","level":"info","event":"/opt/spark/bin/load-spark-env.sh: line 68: ps: command not found","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:48:16.166806","level":"info","event":"Setting default log level to \"WARN\".","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:48:16.169535","level":"info","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:49:39.874717","level":"info","event":"25/08/11 00:48:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:49:42.533667","level":"info","event":"\r[Stage 0:>                                                          (0 + 1) / 1]","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:49:42.623239","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.446910","level":"info","event":"\r[Stage 2:>                                                          (0 + 1) / 1]","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.484260","level":"info","event":"\r[Stage 4:>                                                          (0 + 0) / 1]","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.485194","level":"info","event":"\r[Stage 4:>                                                          (0 + 1) / 1]\r\r[Stage 7:>                                                          (0 + 1) / 1]\r\r[Stage 7:>                                                          (0 + 1) / 1]\r\r[Stage 11:>                                                         (0 + 1) / 1]\rERROR:root:Exception while sending command.","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.486194","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.486569","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.487022","level":"info","event":"    raise Py4JNetworkError(\"Answer from Java side is empty\")","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.487245","level":"info","event":"py4j.protocol.Py4JNetworkError: Answer from Java side is empty","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.487407","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.487557","level":"info","event":"During handling of the above exception, another exception occurred:","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.488510","level":"info","event":"","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.488693","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.488848","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.489094","level":"info","event":"    response = connection.send_command(command)","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.489321","level":"info","event":"               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.489535","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.490280","level":"info","event":"    raise Py4JNetworkError(","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.490475","level":"info","event":"py4j.protocol.Py4JNetworkError: Error while sending or receiving","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.490636","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.490816","level":"info","event":"  File \"/app/process_data.py\", line 100, in <module>","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.490988","level":"info","event":"    df.write.mode(\"overwrite\").parquet(\"/app/output/reviews_processed.parquet\")","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.491168","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/pyspark/sql/readwriter.py\", line 1721, in parquet","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.491331","level":"info","event":"    self._jwrite.parquet(path)","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.491584","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.491816","level":"info","event":"    return_value = get_return_value(","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.491978","level":"info","event":"                   ^^^^^^^^^^^^^^^^^","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.492137","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.492412","level":"info","event":"    return f(*a, **kw)","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.492579","level":"info","event":"           ^^^^^^^^^^^","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.492747","level":"info","event":"  File \"/usr/local/lib/python3.11/site-packages/py4j/protocol.py\", line 334, in get_return_value","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.492915","level":"info","event":"    raise Py4JError(","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:24.493159","level":"info","event":"py4j.protocol.Py4JError: An error occurred while calling o141.parquet","logger":"airflow.task.operators.airflow.providers.docker.operators.docker.DockerOperator"}
{"timestamp":"2025-08-11T00:52:40.196484","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"DockerContainerFailedException","exc_value":"Docker container failed: {'StatusCode': 1}","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":838,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1130,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py","lineno":494,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py","lineno":367,"name":"_run_image"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py","lineno":428,"name":"_run_image_with_mounts"}]},{"exc_type":"APIError","exc_value":"400 Client Error for http+docker://localhost/v1.49/containers/create: Bad Request (\"invalid mount config for type \"bind\": bind source path does not exist: /tmp/airflowtmpj9xjgy_n\")","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py","lineno":358,"name":"_run_image"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py","lineno":385,"name":"_run_image_with_mounts"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py","lineno":440,"name":"create_container"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/docker/api/container.py","lineno":457,"name":"create_container_from_config"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py","lineno":281,"name":"_result"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py","lineno":277,"name":"_raise_for_status"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/docker/errors.py","lineno":39,"name":"create_api_error_from_http_exception"}]},{"exc_type":"HTTPError","exc_value":"400 Client Error: Bad Request for url: http+docker://localhost/v1.49/containers/create","exc_notes":[],"syntax_error":null,"is_cause":true,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/docker/api/client.py","lineno":275,"name":"_raise_for_status"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/requests/models.py","lineno":1024,"name":"raise_for_status"}]}]}
